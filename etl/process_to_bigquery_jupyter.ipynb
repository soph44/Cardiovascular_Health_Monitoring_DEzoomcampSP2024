{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88b121da-0745-41f6-a18f-697a530ef18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import types\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.sql.functions import spark_partition_id \n",
    "from pyspark.context import SparkContext\n",
    "from google.cloud import storage\n",
    "from google.cloud import bigquery as bq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02984cf8-f488-421f-833a-d03d18e0ffd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_bqtable_exists(client, table_id):\n",
    "    try:\n",
    "        client.get_table(table_id)\n",
    "        return True\n",
    "    except:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c73258e7-a5ff-48cb-93fa-a01bdddb02eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputYear = 2019\n",
    "inputYear = str(inputYear)\n",
    "keyLocation = '/Users/sonny/Git/de_zoomcamp_project_2024_SP/keys/cvd-key.json'\n",
    "bucketName = 'cvd-bucket-de2024'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72e75c3e-1564-4c8a-8039-d79ee7ece3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create BigQuery Output External Table if not already existing, includes defined schema\n",
    "client = bq.Client()\n",
    "table_id = \"cvd-sp-de-zoomcamp-2024.cvd_dataset.bq_output_table\"\n",
    "tableExists = check_bqtable_exists(client, table_id)\n",
    "if tableExists == False:\n",
    "    schema = [\n",
    "        bq.SchemaField(\"Key\", \"STRING\"),\n",
    "        bq.SchemaField(\"Year\", \"INTEGER\"),\n",
    "        bq.SchemaField(\"Locationdesc\", \"STRING\"),\n",
    "        bq.SchemaField(\"Question\", \"STRING\"),\n",
    "        bq.SchemaField(\"Response\", \"STRING\"),\n",
    "        bq.SchemaField(\"Break_Out\", \"STRING\"),\n",
    "        bq.SchemaField(\"Break_Out_Category\", \"STRING\"),\n",
    "        bq.SchemaField(\"Sample_Size\", \"INTEGER\"),\n",
    "        bq.SchemaField(\"Data_value\", \"FLOAT\"),\n",
    "        bq.SchemaField(\"LocationID\", \"STRING\"),\n",
    "        bq.SchemaField(\"BreakoutID\", \"STRING\"),\n",
    "        bq.SchemaField(\"BreakOutCategoryID\", \"STRING\"),\n",
    "        bq.SchemaField(\"QuestionID\", \"STRING\"),\n",
    "    ]\n",
    "    dataset = bq.Dataset(\"cvd-sp-de-zoomcamp-2024.cvd_dataset\")\n",
    "    dataset.location = \"US\"\n",
    "    dataset = client.create_dataset(dataset, timeout=30)\n",
    "    new_table = bq.Table(table_id, schema=schema)\n",
    "    new_table = client.create_table(new_table) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "feafc44b-0eb4-4913-a146-e1fd12e5a8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = SparkConf() \\\n",
    "    .setMaster('local[*]') \\\n",
    "    .setAppName('cvdPipeline') \\\n",
    "    .set(\"spark.jars\", \"./lib/gcs-connector-hadoop3-2.2.5.jar,./lib/spark-3.5-bigquery-0.37.0.jar\") \\\n",
    "    .set(\"spark.hadoop.google.cloud.auth.service.account.enable\", \"true\") \\\n",
    "    .set(\"spark.hadoop.google.cloud.auth.service.account.json.keyfile\", keyLocation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "018f0586-d741-4194-b166-8a049b48c456",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/08 22:16:12 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/04/08 22:17:04 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n",
      "24/04/08 22:17:06 ERROR Inbox: Ignoring error\n",
      "java.lang.NullPointerException: Cannot invoke \"org.apache.spark.storage.BlockManagerId.executorId()\" because \"idWithoutTopologyInfo\" is null\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:677)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "24/04/08 22:17:06 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: java.lang.NullPointerException: Cannot invoke \"org.apache.spark.storage.BlockManagerId.executorId()\" because \"idWithoutTopologyInfo\" is null\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:677)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "24/04/08 22:17:16 ERROR Inbox: Ignoring error\n",
      "java.lang.NullPointerException: Cannot invoke \"org.apache.spark.storage.BlockManagerId.executorId()\" because \"idWithoutTopologyInfo\" is null\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:677)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "24/04/08 22:17:16 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: java.lang.NullPointerException: Cannot invoke \"org.apache.spark.storage.BlockManagerId.executorId()\" because \"idWithoutTopologyInfo\" is null\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:677)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "24/04/08 22:17:26 ERROR Inbox: Ignoring error\n",
      "java.lang.NullPointerException: Cannot invoke \"org.apache.spark.storage.BlockManagerId.executorId()\" because \"idWithoutTopologyInfo\" is null\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:677)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "24/04/08 22:17:26 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: java.lang.NullPointerException: Cannot invoke \"org.apache.spark.storage.BlockManagerId.executorId()\" because \"idWithoutTopologyInfo\" is null\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:677)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n"
     ]
    }
   ],
   "source": [
    "sc = SparkContext(conf=conf)\n",
    "hadoop_conf = sc._jsc.hadoopConfiguration()\n",
    "hadoop_conf.set(\"fs.AbstractFileSystem.gs.impl\",  \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS\")\n",
    "hadoop_conf.set(\"fs.gs.impl\", \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem\")\n",
    "hadoop_conf.set(\"fs.gs.auth.service.account.json.keyfile\", keyLocation)\n",
    "hadoop_conf.set(\"fs.gs.auth.service.account.enable\", \"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7f6f87f-06ab-404e-8014-a2fd8d18dd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .config(conf=sc.getConf()) \\\n",
    "    .getOrCreate()\n",
    "spark.conf.set('temporaryGcsBucket', bucketName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b31b940e-0711-481e-acf6-d9bb33658dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_id = \"cvd-sp-de-zoomcamp-2024.cvd_dataset.bq_output_table\"\n",
    "dfbq = spark.read.format('bigquery') \\\n",
    "    .option('table', table_id) \\\n",
    "    .option(\"credentialsFile\", keyLocation) \\\n",
    "    .option(\"header\", True) \\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28a3ca4b-905c-40a3-a630-2b11c8b30369",
   "metadata": {},
   "outputs": [],
   "source": [
    "colRead = ['Key', 'Year', 'Locationdesc', 'Question', 'Response', \\\n",
    "           'Break_Out', 'Break_Out_Category', 'Sample_Size', 'Data_value',  \\\n",
    "           'LocationID', 'BreakoutID', 'BreakOutCategoryID', 'QuestionID'\n",
    "           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e2239bd-36a8-4b9d-a693-09b8b311a42b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "dfnew = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .parquet('gs://cvd-bucket-de2024/cdc_data_' + inputYear + '.parquet') \\\n",
    "    .select(colRead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6583068d-feb5-4ec3-9a3f-a59186850b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop rows where any filtered column values are NULL\n",
    "dfnew = dfnew.dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ba03191-8c35-4281-bc53-d955916e171e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfjoin = dfbq.union(dfnew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8ebff75-e77f-4dce-96d8-853d7a31749b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfpc = dfjoin.repartition(6, \"Break_Out_Category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0394864c-e468-45b8-a0d2-eb539ac5d50b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|partitionId|count|\n",
      "+-----------+-----+\n",
      "|          0| 7718|\n",
      "|          1| 6511|\n",
      "|          2| 9970|\n",
      "|          3|11008|\n",
      "+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Review partitions made\n",
    "dfpc.rdd.getNumPartitions()\n",
    "dfpc.withColumn(\"partitionId\", spark_partition_id()).groupBy(\"partitionId\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45839fce-5274-48d6-b56b-6f52d1f8ebfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/08 22:18:49 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "dfpc.write.format(\"bigquery\")\\\n",
    "    .option(\"temporaryGcsBucket\",bucketName)\\\n",
    "    .option(\"credentialsFile\", keyLocation) \\\n",
    "    .option(\"header\", True) \\\n",
    "    .mode(\"overwrite\")\\\n",
    "    .save(path=table_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62d3fcef-58a1-40b9-9515-c18a8d38d27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02536893-339e-4da1-9c44-069292f3dc9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467102c6-37e7-4e06-a80a-3412fecbaae0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
